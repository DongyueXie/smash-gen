---
title: "Poisson sequence with Spike mean"
author: "Dongyue Xie"
date: "May 21, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = F, message = F)
```

From the [Poisson sequence with unknown variance](poiunknown.html) simulations, we notice that 1. smashgen performs poorly when the mean function has sudden changes like spikes; 2. smashgen is not as good as `smash.pois` sometimes when $\sigma$ is small and the range of mean function is small.

The performance of smashgen is worse than `smash.pois` for spike mean, especialy when the range of $\mu$ is small. Smashgen cannot capture the spikes properly which results in huge squared errors. The `smash.pois` could capture the spikes and it gives noisy fit for the low mean area so it's MSE is much smaller. Let's figure out the reason.

One possible reason that causes the issue is that smashgen gives very large fit to the spikes.  

Plots of smashgen smoothed wavelets. Blue curves are from smashgen and the black ones are truth.

```{r}
library(smashrgen)
spike.f = function(x) (0.75 * exp(-500 * (x - 0.23)^2) + 1.5 * exp(-2000 * (x - 0.33)^2) + 3 * exp(-8000 * (x - 0.47)^2) + 2.25 * exp(-16000 * 
    (x - 0.69)^2) + 0.5 * exp(-32000 * (x - 0.83)^2))
n = 256
t = 1:n/n
m = spike.f(t)

m=m*2+0.1
range(m)
m=log(m)

sigma=0.1
set.seed(12345)
lamda=exp(m+rnorm(length(m),0,sigma))
x=rpois(length(m),lamda)
x.fit=smash_gen(x)
plot(x,col='gray80',main='sigma=0.1')
lines(exp(m))
lines(x.fit,col=4)
```

To figure out the reason, we make the following plot.

```{r,fig.width=12,fig.height=7}
x.ash=ash(rep(0,n),1,lik=lik_pois(x))$result$PosteriorMean
y=log(x.ash)+(x-x.ash)/x.ash
plot(x,col='gray80',ylim = c(-2,10))
lines(exp(m))
lines(x.ash,col=4)
lines(y,col=3,type = 'p',pch=1)
lines(m,col=2)
lines(log(x.fit),col=2,lty=2)
legend('topright',
       c('data','true mean','ash shrinked','normal approx data','true normal mean','smashgen normal mean'),
       lty=c(0,1,1,0,1,2),
       pch=c(1,NA,NA,1,NA,NA),
       
       cex=1,col=c('gray80',1,4,3,2,2))
```

$\sigma=1$

```{r,fig.width=12,fig.height=7}
sigma=1
set.seed(12345)
lamda=exp(m+rnorm(length(m),0,sigma))
x=rpois(length(m),lamda)
x.fit=smash_gen(x)
plot(x,col='gray80',main='sigma=1')
lines(exp(m))
lines(x.fit,col=4)
x.ash=ash(rep(0,n),1,lik=lik_pois(x))$result$PosteriorMean
y=log(x.ash)+(x-x.ash)/x.ash
plot(x,col='gray80',ylim = c(-2,10))
lines(exp(m))
lines(x.ash,col=4)
lines(y,col=3,type = 'p',pch=1)
lines(m,col=2)
lines(log(x.fit),col=2,lty=2)
legend('topright',
       c('data','true mean','ash shrinked','normal approx data','true normal mean','est normal mean'),
       lty=c(0,1,1,0,1,2),
       pch=c(1,NA,NA,1,NA,NA),
       
       cex=1,col=c('gray80',1,4,3,2,2))
```

If we use the robust version:

```{r}
par(mfrow=c(1,2))
sigma=0.1
set.seed(12345)
lamda=exp(m+rnorm(length(m),0,sigma))
x=rpois(length(m),lamda)
x.fit=smash_gen(x,robust = T)
plot(x,col='gray80',main='sigma=0.1')
lines(exp(m))
lines(x.fit,col=4)
sigma=1
set.seed(12345)
lamda=exp(m+rnorm(length(m),0,sigma))
x=rpois(length(m),lamda)
x.fit=smash_gen(x,robust = T)
plot(x,col='gray80',main='simga=1')
lines(exp(m))
lines(x.fit,col=4)
```

It does not help for now.

It seems that ash shrinks the data to the mean too much such that the normal approximated data consistently larger than what we want.

If we don't use the ash shinkage and use more iterations:

```{r}
par(mfrow=c(1,2))
sigma=0.1
set.seed(12345)
lamda=exp(m+rnorm(length(m),0,sigma))
x=rpois(length(m),lamda)
x.fit=smash_gen(x,robust = T,ashp = F,niter=20,verbose = T)
plot(x,col='gray80',main='sigma=0.1')
lines(exp(m))
lines(x.fit,col=4)
sigma=1
set.seed(12345)
lamda=exp(m+rnorm(length(m),0,sigma))
x=rpois(length(m),lamda)
x.fit=smash_gen(x,robust = T,ashp = F,niter=20,verbose = T)
plot(x,col='gray80',main='simga=1')
lines(exp(m))
lines(x.fit,col=4)
```

Still, the algorithm does not converge so we still see the huge spike on the plot.

# Signal to noise ratio is too high!

When the range of mean function is around $(0.1,6)$, the signal to noise ratio is too high.
```{r,fig.width=14,fig.height=8}
par(mfrow=c(1,2))
plot(1/exp(m)+0.1,type='l',col=4,ylim=c(0,11),main='sigma=0.1',ylab='variance')
lines(rep(var(m),n),type='l')
legend('bottomright',c('noise','signal'),lty=c(1,1),col=c(4,1))
plot(1/exp(m)+1,type='l',col=4,ylim=c(0,11),main='sigma=1',ylab='variance')
lines(rep(var(m),n),type='l')
#legend('bottomright',c('noise','signal'),lty=c(1,1),col=c(4,1))
```

If we choose $\mu$ in around $(0.1,60)$:
```{r}
m = spike.f(t)

m=m*20+0.1
m=log(m)
range(exp(m))

par(mfrow=c(1,2))
plot(1/exp(m)+0.1,type='l',col=4,ylim=c(0,11),main='sigma=0.1',ylab='variance')
lines(rep(var(m),n),type='l')
legend('bottomright',c('noise','signal'),lty=c(1,1),col=c(4,1))
plot(1/exp(m)+1,type='l',col=4,ylim=c(0,11),main='sigma=1',ylab='variance')
lines(rep(var(m),n),type='l')
```

Then the 'spike' issue disappears:
```{r}
par(mfrow=c(1,2))
sigma=0.1
set.seed(12345)
lamda=exp(m+rnorm(length(m),0,sigma))
x=rpois(length(m),lamda)
x.fit=smash_gen(x,robust = T)
plot(x,col='gray80',main='sigma=0.1')
lines(exp(m))
lines(x.fit,col=4)
sigma=1
set.seed(12345)
lamda=exp(m+rnorm(length(m),0,sigma))
x=rpois(length(m),lamda)
x.fit=smash_gen(x,robust = T)
plot(x,col='gray80',main='simga=1')
lines(exp(m))
lines(x.fit,col=4)
```
