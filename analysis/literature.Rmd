---
title: "Literature review of smoothing non-Gaussian sequence data "
author: "Dongyue Xie"
date: "2018-09-29"
output: workflowr::wflow_html
---



This is a broad list of literature on smoothing Gaussian/non-Gaussian data.

## Nonparametric methods

1. KNN

2. Kernel smootihng methods: Chapter 6 of [ESL](https://web.stanford.edu/~hastie/ElemStatLearn/).

3. Local regression(linear & higher order): [Loader, C. (2006). Local regression and likelihood. Springer Science & Business Media.](http://web.ipac.caltech.edu/staff/fmasci/home/astro_refs/LocalRegressionBook_1999.pdf)

Note: Local regression makes no global assumptions about the function but assume that locally it can be well approximated with a member of a simple class of parametric function. Only observations in certain window are used.

4. Splines: regression splines, smoothing splines; More generally, reproducing kernel Hilbert space: Chapter 5 of [ESL](https://web.stanford.edu/~hastie/ElemStatLearn/)

5. Locally adaptive estimators: wavelet( [Mallat, S. (1999). A wavelet tour of signal processing. Elsevier](https://www.di.ens.fr/~mallat/papiers/WaveletTourChap1-2-3.pdf) ), Locally adaptive regression splines(A varaiant of smooting splines achieves better local adaptivity. [Mammen, E., & van de Geer, S. (1997). Locally adaptive regression splines. The Annals of Statistics, 25(1), 387-413.](https://projecteuclid.org/euclid.aos/1034276635)), Trend filtering( [Kim, S. J., Koh, K., Boyd, S., & Gorinevsky, D. (2009). l_1 Trend Filtering. SIAM review, 51(2), 339-360.](http://web.stanford.edu/~boyd/papers/l1_trend_filter.html) ).

6. Additive models: Sparse additive models, Generalized additive mixed models.

More on trend filtering and additive models:

Trend filtering:

[Wang, Y. X., Sharpnack, J., Smola, A. J., & Tibshirani, R. J. (2016). Trend filtering on graphs. The Journal of Machine Learning Research, 17(1), 3651-3691.](http://www.jmlr.org/papers/volume17/15-147/15-147.pdf)

[Ramdas, A., & Tibshirani, R. J. (2016). Fast and flexible ADMM algorithms for trend filtering. Journal of Computational and Graphical Statistics, 25(3), 839-858.](https://www.tandfonline.com/doi/abs/10.1080/10618600.2015.1054033) The R package for this algo is glmgen.

[Tibshirani, R. J. (2014). Adaptive piecewise polynomial estimation via trend filtering. The Annals of Statistics, 42(1), 285-323.](http://www.stat.cmu.edu/~ryantibs/papers/trendfilter.pdf)

Additive models:

[Sadhanala, V., & Tibshirani, R. J. (2017). Additive Models with Trend Filtering. arXiv preprint arXiv:1702.05037.](http://www.stat.cmu.edu/~ryantibs/papers/additivetf.pdf)

[Petersen, A., Witten, D., & Simon, N. (2016). Fused lasso additive model. Journal of Computational and Graphical Statistics, 25(4), 1005-1025.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5321231/)

[Yin Lou, Jacob Bien, Rich Caruana & Johannes Gehrke (2016) Sparse Partially Linear Additive Models, Journal of Computational and Graphical Statistics, 25:4, 1126-1140](https://amstat.tandfonline.com/doi/full/10.1080/10618600.2015.1089775#.W8J4Ci2ZPfZ)

[Generalized Sparse Additive Models](http://faculty.chicagobooth.edu/workshops/econometrics/pdf/pdf/Fall%202018/Shojaie,%20GSAM.pdf)

[Chouldechova, A., & Hastie, T. (2015). Generalized additive model selection. arXiv preprint arXiv:1506.03850.](https://web.stanford.edu/~hastie/Papers/gamsel.pdf)


## Exponential family

Nonparametric regression for exponential family:

[Brown, Lawrence D., T. Tony Cai, and Harrison H. Zhou. "Nonparametric regression in exponential families." The annals of statistics 38.4 (2010): 2005-2046.](https://arxiv.org/pdf/1010.3836.pdf)

[Cleveland, W. S., Mallows, C. L., & McRae, J. E. (1993). ATS methods: Nonparametric regression for non-Gaussian data. Journal of the American Statistical Association, 88(423), 821-835.](https://www.jstor.org/stable/pdf/2290771.pdf?refreqid=excelsior%3A9899f3e009de18206db09c6eec5a069c)

[Zhang, H. H., & Lin, Y. (2006). Component selection and smoothing for nonparametric regression in exponential families. Statistica Sinica, 1021-1041.](http://www3.stat.sinica.edu.tw/statistica/oldpdf/A16n317.pdf)

[Bianco, A. M., Boente, G., & Sombielle, S. (2011). Robust estimation for nonparametric generalized regression. Statistics & Probability Letters, 81(12), 1986-1994.](https://www.sciencedirect.com/science/article/pii/S0167715211002719)

[Fryzlewicz, P. (2017). Likelihood ratio Haar variance stabilization and normalization for Poisson and other non-Gaussian noise removal. arXiv preprint arXiv:1701.07263.](https://arxiv.org/pdf/1701.07263.pdf)

[Local Likelihood Estimation](https://www.jstor.org/stable/pdf/2289465.pdf)

Generalized addtive model

[O'sullivan, F., Yandell, B. S., & Raynor Jr, W. J. (1986). Automatic smoothing of regression functions in generalized linear models. Journal of the American Statistical Association, 81(393), 96-103.](http://www.stat.wisc.edu/~yandell/doc/1986/7.JASA.pdf)


## Poisson

[Kolaczyk, E. (1999). Bayesian Multiscale Models for Poisson Processes. Journal of the American Statistical Association, 94(447), 920-933. doi:10.2307/2670007](https://www.jstor.org/stable/2670007?seq=1#metadata_info_tab_contents)

[Fryzlewicz, P., & Nason, G. P. (2004). A Haar-Fisz algorithm for Poisson intensity estimation. Journal of computational and graphical statistics, 13(3), 621-638.](http://stats.lse.ac.uk/fryzlewicz/Poisson/jcgs.pdf)

[Timmerman, K., & Nowak, R. D. (1999). Multiscale modeling and estimation of Poisson processes with application to photon-limited imaging. IEEE Transactions on Information Theory, 45(3), 846-842.](https://ieeexplore.ieee.org/document/761328)

## Binomial

[Marchand, P., & Marmet, L. (1983). Binomial smoothing filter: A way to avoid some pitfalls of least‚Äêsquares polynomial smoothing. Review of scientific instruments, 54(8), 1034-1041. ](https://aip.scitation.org/doi/10.1063/1.1137498)

[Hansen, K. D., Langmead, B., & Irizarry, R. A. (2012). BSmooth: from whole genome bisulfite sequencing reads to differentially methylated regions. Genome biology, 13(10), R83.](https://genomebiology.biomedcentral.com/articles/10.1186/gb-2012-13-10-r83#Abs1)

Note: It actually uses local likelihood moother and assumes $logit(\pi)$ is approximated by a second degree polynomial. They assume that data follow a binomial distribution and the parameters defining the polynomial are estimated by fitting a weighted generalized linear model to the data inside the genomic window.

